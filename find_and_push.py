import os
import requests
import asyncio
import yaml
from bs4 import BeautifulSoup
from telegram import Bot
from telegram.constants import ParseMode
import urllib.parse

BOT_TOKEN = os.getenv("BOT_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID")

STATIC_SUBSCRIBE_URLS = [
    "https://wanmeiwl3.xyz/gywl/4e3979fc330fc6b7806f3dc78a696f10",
    "https://bestsub.bestrui.ggff.net/share/bestsub/cdcefaa4-1f0d-462e-ba76-627b344989f2/all.yaml",
    "https://linuxdo.miaoqiqi.me/linuxdo/love",
    "https://bh.jiedianxielou.workers.dev",
    "https://raw.githubusercontent.com/mfuu/v2ray/master/clash.yaml",
    "https://raw.githubusercontent.com/anaer/Sub/main/clash.yaml",
    "https://raw.githubusercontent.com/ermaozi/get_subscribe/main/subscribe/clash.yml",
    "https://cdn.jsdelivr.net/gh/vxiaov/free_proxies@main/clash/clash.provider.yaml",
    "https://freenode.openrunner.net/uploads/20240617-clash.yaml",
    "https://tt.vg/freeclash",
    "https://raw.githubusercontent.com/SnapdragonLee/SystemProxy/master/dist/clash_config.yaml"
]

def validate_subscription(url):
    try:
        res = requests.get(url, timeout=10)
        if res.status_code == 200 and "proxies" in res.text:
            return True
    except:
        pass
    return False

def search_github_clash_urls():
    print("ğŸ” GitHub æœç´¢è®¢é˜…æ–‡ä»¶ä¸­...")
    try:
        headers = {
            "Accept": "application/vnd.github.v3.text-match+json"
        }
        query = "clash filename:clash.yaml in:path extension:yaml"
        url = f"https://api.github.com/search/code?q={query}&per_page=100"
        res = requests.get(url, headers=headers, timeout=15)
        items = res.json().get("items", [])
        links = []
        for item in items:
            raw_url = item["html_url"].replace("github.com", "raw.githubusercontent.com").replace("/blob/", "/")
            links.append(raw_url)
        print(f"âœ¨ GitHub æœç´¢åˆ° {len(links)} ä¸ªå¯èƒ½çš„è®¢é˜…é“¾æ¥")
        return links
    except Exception as e:
        print("GitHub æœç´¢å¤±è´¥:", e)
        return []

def get_subscription_country_info(url):
    try:
        res = requests.get(url, timeout=10)
        if res.status_code != 200:
            return None

        data = yaml.safe_load(res.text)
        proxies = data.get("proxies", [])
        countries = set()

        for proxy in proxies:
            country = proxy.get("country")
            if country and isinstance(country, str) and len(country) <= 5:
                countries.add(country.strip())
                continue

            region = proxy.get("region")
            if region and isinstance(region, str) and len(region) <= 5:
                countries.add(region.strip())
                continue

            name = proxy.get("name") or proxy.get("remark") or proxy.get("remarks")
            if name and isinstance(name, str) and len(name) >= 2:
                countries.add(name[:2].strip())

        return ", ".join(sorted(countries)) if countries else None
    except Exception as e:
        print(f"è§£æèŠ‚ç‚¹åœ°åŒºå¤±è´¥ï¼š{url}ï¼Œé”™è¯¯ï¼š{e}")
        return None

def fetch_nodefree_links():
    print("ğŸŒ æ­£åœ¨æŠ“å– nodefree.net æœ€æ–°èŠ‚ç‚¹...")
    try:
        base_url = "https://nodefree.net"
        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(base_url, headers=headers, timeout=15)
        soup = BeautifulSoup(resp.text, 'html.parser')

        post_link = None
        for a in soup.find_all('a'):
            if 'å…è´¹èŠ‚ç‚¹' in a.text:
                post_link = a['href']
                break

        if not post_link:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ€æ–°èŠ‚ç‚¹æ–‡ç« ")
            return []

        full_url = post_link if post_link.startswith("http") else base_url + post_link
        res = requests.get(full_url, headers=headers, timeout=15)
        soup = BeautifulSoup(res.text, 'html.parser')

        found_links = []
        for a in soup.find_all('a'):
            href = a.get('href', '')
            if href.startswith("http") and (".yaml" in href or "vmess://" in href or "ss://" in href):
                found_links.append(href.strip())

        print(f"ğŸ“¥ nodefree.net æå–åˆ° {len(found_links)} ä¸ªè®¢é˜…é“¾æ¥")
        return found_links
    except Exception as e:
        print("âŒ æŠ“å– nodefree.net å¤±è´¥:", e)
        return []

async def send_to_telegram(bot_token, channel_id, urls):
    if not urls:
        print("âŒ æ²¡æœ‰å¯ç”¨èŠ‚ç‚¹ï¼Œè·³è¿‡æ¨é€")
        return

    text = "ğŸ†• <b>2025å¹´æœ€æ–°Clashè®¢é˜…èŠ‚ç‚¹ å…è´¹vpnèŠ‚ç‚¹Clash/V2Ray/Shadowsocks/Vmessè®¢é˜…æ›´æ–° é€‚åˆç¿»å¢™ç§‘å­¦ä¸Šç½‘ã€å…è´¹é«˜é€ŸV2RayèŠ‚ç‚¹æ¨èèŠ‚ç‚¹è®¢é˜…</b>\n\n"
    for i, url in enumerate(urls[:20], start=1):
        country_info = get_subscription_country_info(url)
        if country_info:
            country_info = f"ï¼ˆèŠ‚ç‚¹åœ°åŒº: {country_info}ï¼‰"
        else:
            country_info = ""

        safe_url = urllib.parse.quote(url, safe=":/?=&")
        text += f"ğŸ‘‰ <a href=\"{safe_url}\">{url}</a> {country_info}\nï¼ˆå¯é•¿æŒ‰å¤åˆ¶ï¼Œæˆ–ç²˜è´´åˆ° Clash / Shadowrocket å¯¼å…¥ï¼‰\n\n"

    if len(text.encode('utf-8')) > 4000:
        text = text.encode("utf-8")[:4000].decode("utf-8", errors="ignore") + "\n..."

    bot = Bot(token=bot_token)
    try:
        await bot.send_message(chat_id=channel_id, text=text, parse_mode=ParseMode.HTML, disable_web_page_preview=True)
        print("âœ… æ¨é€æˆåŠŸ")
    except Exception as e:
        print("âŒ æ¨é€å¤±è´¥:", e)

async def main():
    if not BOT_TOKEN or not CHANNEL_ID:
        print("ç¯å¢ƒå˜é‡ BOT_TOKEN æˆ– CHANNEL_ID æœªè®¾ç½®")
        return

    print("ğŸ” éªŒè¯é™æ€è®¢é˜…é“¾æ¥...")
    valid_static = [url for url in STATIC_SUBSCRIBE_URLS if validate_subscription(url)]

    github_links = search_github_clash_urls()
    print("ğŸ” éªŒè¯ GitHub æœç´¢åˆ°çš„è®¢é˜…é“¾æ¥...")
    valid_dynamic = [url for url in github_links if validate_subscription(url)]

    nodefree_links = fetch_nodefree_links()
    print("ğŸ” éªŒè¯ nodefree.net è·å–åˆ°çš„é“¾æ¥...")
    valid_nodefree = [url for url in nodefree_links if validate_subscription(url)]

    all_valid = list(set(valid_static + valid_dynamic + valid_nodefree))
    print(f"âœ”ï¸ å…±éªŒè¯é€šè¿‡çš„æœ‰æ•ˆè®¢é˜…é“¾æ¥æ•°é‡: {len(all_valid)}")

    with open("valid_links.txt", "w") as f:
        for link in all_valid:
            f.write(link + "\n")
    print("ğŸ“„ å·²ä¿å­˜åˆ° valid_links.txt")

    await send_to_telegram(BOT_TOKEN, CHANNEL_ID, all_valid)

if __name__ == "__main__":
    asyncio.run(main())
